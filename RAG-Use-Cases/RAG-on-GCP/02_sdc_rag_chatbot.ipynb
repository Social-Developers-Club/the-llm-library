{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a621832-23d5-4dd4-a2eb-33dfad86030b",
   "metadata": {},
   "source": [
    "# SDC SocialMedia Assist RAG + Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd009ad-a013-408b-a22f-bb58853eff69",
   "metadata": {},
   "source": [
    "## Import Libs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d133d1-f425-410d-8837-521f45d629dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.globals import set_debug\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_community import BigQueryVectorStore, VertexFSVectorStore,GCSFileLoader\n",
    "from langchain_google_vertexai import VertexAI, VertexAIEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from google.cloud import storage\n",
    "import io\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\"config/config.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11077e62-103e-4842-9994-5897b5ef9240",
   "metadata": {},
   "source": [
    "## Loading Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ab972e-fb29-4faa-8445-8c5297e9494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = config[\"PROJECT_ID\"]\n",
    "LOCATION = config[\"LOCATION\"]\n",
    "\n",
    "# CloudStorage\n",
    "BUCKET_NAME = config[\"BUCKET_NAME\"]\n",
    "BLOB_NAME = config[\"BLOB_NAME\"]\n",
    "\n",
    "# BigQuery\n",
    "DATASET_ID = config[\"DATASET_ID\"]\n",
    "TABLE_ID = config[\"TABLE_ID\"]\n",
    "\n",
    "# Models\n",
    "MODEL_NAME = config[\"MODEL_NAME\"]\n",
    "EMBEDDING_MODEL = config[\"EMBEDDING_MODEL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71bf360-c561-4c1f-b256-e536af7afd23",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c56faa0-1a5e-414b-b6b8-ff7552b67f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_embedding_model(embedding_model, project_id):\n",
    "    \n",
    "    embedding_model = VertexAIEmbeddings(\n",
    "        model_name=embedding_model, project=project_id\n",
    "    )\n",
    "    \n",
    "    return embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d21e68-2e29-45bf-9719-cff0475e12fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bqvector(project_id, location, dataset_id, table_id, embedding_model):\n",
    "    bq_store = BigQueryVectorStore(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        dataset_name=dataset_id,\n",
    "        table_name=table_id,\n",
    "        embedding=embedding_model,\n",
    "    )\n",
    "    return bq_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a2f6a7-aeb5-4553-a31d-7272cc2c1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_system_prompt():\n",
    "    \n",
    "    # Define your custom prompt\n",
    "    custom_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    "        template=\"\"\"\n",
    "        Du bist ein hilfsbereiter KI-Assistent für unser Unternehmen, spezialisiert auf Social-Media-Strategien und die Einarbeitung neuer Teammitglieder. \n",
    "        Nutze das vorhandene Wissen aus dem Kontext, um präzise und nützliche Antworten zu liefern.\n",
    "\n",
    "        Gesprächsverlauf:\n",
    "        {chat_history}\n",
    "\n",
    "        Kontext:\n",
    "        {context}\n",
    "\n",
    "        Frage:\n",
    "        {question}\n",
    "\n",
    "        Bitte beachte bei deiner Antwort:\n",
    "        - Gehe spezifisch auf die Bedürfnisse des Nutzers ein.\n",
    "        - Nur auf Nachfrage! Biete praktische Tipps für Social-Media-Posts im Unternehmenskontext.\n",
    "        - Unterstütze neue Kollegen mit klaren Anweisungen und Ressourcen.\n",
    "        - Verwende eine positive und motivierende Sprache.\n",
    "        - Halte dich kurze und beantworte im ersten schritt erst mal nur die Nutzer-Frage.\n",
    "        - Gebe mir Antwort wenn passend als Aufzählung auf.\n",
    "\n",
    "        Antwort:\n",
    "        \"\"\"\n",
    "        )\n",
    "    return custom_prompt\n",
    "\n",
    "def initialize_llm_model(model_name):\n",
    "    # Initialize the LLM\n",
    "    llm = VertexAI(model_name=model_name)\n",
    "    \n",
    "    return llm\n",
    "\n",
    "def create_memory_buffer():\n",
    "    # Set up the conversation memory\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        input_key=\"question\",\n",
    "        output_key=\"answer\",\n",
    "        return_messages=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return memory\n",
    "\n",
    "def convo_chain(llm, langchain_retriever, memory, custom_prompt):\n",
    "    # Set up the ConversationalRetrievalChain with the custom prompt\n",
    "    conversational_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=langchain_retriever,\n",
    "        memory=memory,\n",
    "        combine_docs_chain_kwargs={\"prompt\": custom_prompt},\n",
    "        # verbose=True\n",
    "    )\n",
    "    \n",
    "    return conversational_chain\n",
    "\n",
    "# Function to interact with the agent\n",
    "def chat_with_agent(conversational_chain):\n",
    "    print(\"Start chatting with the agent (type 'exit' to stop):\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        response = conversational_chain.invoke({\"question\": user_input})\n",
    "        print(f\"\\nAssistant: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb74e8-4c4e-4e1a-a13e-69f560a3f305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a7b019-a5ca-480e-afc3-d370dc070a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 - Initialize embedding model\n",
      "02 - Initialize BQVector Storage\n",
      "BigQuery table sdc-gen-ai.sdc_marketing.sdc_instagram_guideline initialized/validated as persistent storage. Access via BigQuery console:\n",
      " https://console.cloud.google.com/bigquery?project=sdc-gen-ai&ws=!1m5!1m4!4m3!1ssdc-gen-ai!2ssdc_marketing!3ssdc_instagram_guideline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_89445/3798123653.py:40: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03 - Langchain retriever\n",
      "04 - Build System Prompt\n",
      "05 - Initialize LLM model\n",
      "06 - Initialize meory\n",
      "07 - Conversational chain\n",
      "Start chatting with the agent (type 'exit' to stop):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  was sind die Technische Hintergünde für einen beitrag?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "        Du bist ein hilfsbereiter KI-Assistent für unser Unternehmen, spezialisiert auf Social-Media-Strategien und die Einarbeitung neuer Teammitglieder. \n",
      "        Nutze das vorhandene Wissen aus dem Kontext, um präzise und nützliche Antworten zu liefern.\n",
      "\n",
      "        Gesprächsverlauf:\n",
      "        \n",
      "\n",
      "        Kontext:\n",
      "        Skizze: Leitfaden Instagram Postings\n",
      "\n",
      "1. Welchen Zweck hat das Posting? Überleg dir klare Ziele für das Posting 2. Welches Posting-Format (Reel, Story, Beitrag) wählst du? Habe das zugehörige Video-Format im Hinterkopf (s.u. “Technische Hintergründe”) 3. Werte und Ziele - Check! Überprüfe ob dein Vorhaben im Einklang steht: 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23.\n",
      "\n",
      "4. Wie bindest du die Community mit ein? Umfragen, Countdown-Sticker, zum Kommentieren auffordern (z.B. heute haben wir was zu python gelernt….was ist eure liebste Programmiersprache?),... 5. Welche Hashtags passen? Liste Hashtags: 6. Gestaltungsrichtlinen eingehalten?\n",
      "\n",
      "Schriftart: - Sprache (formell /Informell) - Tonalität und Hintergrundmusik - Farbschema: - - Postingstil (minimalistisch, bunt, street, etc.): - Filter und Bildbearbeitung: Logoplatzierung:\n",
      "\n",
      "Technische Hintergünde:\n",
      "\n",
      "Story\n",
      "\n",
      "Videolänge bis zu 15 Sek pro Story - Hochformat (9:16) - Pixelminimum?\n",
      "\n",
      "Beitrag\n",
      "\n",
      "Skizze: Leitfaden Instagram Postings\n",
      "\n",
      "1. Welchen Zweck hat das Posting? Überleg dir klare Ziele für das Posting 2. Welches Posting-Format (Reel, Story, Beitrag) wählst du? Habe das zugehörige Video-Format im Hinterkopf (s.u. “Technische Hintergründe”) 3. Werte und Ziele - Check! Überprüfe ob dein Vorhaben im Einklang steht: 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23.\n",
      "\n",
      "4. Wie bindest du die Community mit ein? Umfragen, Countdown-Sticker, zum Kommentieren auffordern (z.B. heute haben wir was zu python gelernt….was ist eure liebste Programmiersprache?),... 5. Welche Hashtags passen? Liste Hashtags: 6. Gestaltungsrichtlinen eingehalten?\n",
      "\n",
      "Schriftart: - Sprache (formell /Informell) - Tonalität und Hintergrundmusik - Farbschema: - - Postingstil (minimalistisch, bunt, street, etc.): - Filter und Bildbearbeitung: Logoplatzierung:\n",
      "\n",
      "Technische Hintergünde:\n",
      "\n",
      "Story\n",
      "\n",
      "Videolänge bis zu 15 Sek pro Story - Hochformat (9:16) - Pixelminimum?\n",
      "\n",
      "Beitrag\n",
      "\n",
      "Skizze: Leitfaden Instagram Postings\n",
      "\n",
      "1. Welchen Zweck hat das Posting? Überleg dir klare Ziele für das Posting 2. Welches Posting-Format (Reel, Story, Beitrag) wählst du? Habe das zugehörige Video-Format im Hinterkopf (s.u. “Technische Hintergründe”) 3. Werte und Ziele - Check! Überprüfe ob dein Vorhaben im Einklang steht: 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23.\n",
      "\n",
      "4. Wie bindest du die Community mit ein? Umfragen, Countdown-Sticker, zum Kommentieren auffordern (z.B. heute haben wir was zu python gelernt….was ist eure liebste Programmiersprache?),... 5. Welche Hashtags passen? Liste Hashtags: 6. Gestaltungsrichtlinen eingehalten?\n",
      "\n",
      "Schriftart: - Sprache (formell /Informell) - Tonalität und Hintergrundmusik - Farbschema: - - Postingstil (minimalistisch, bunt, street, etc.): - Filter und Bildbearbeitung: Logoplatzierung:\n",
      "\n",
      "Technische Hintergünde:\n",
      "\n",
      "Story\n",
      "\n",
      "Videolänge bis zu 15 Sek pro Story - Hochformat (9:16) - Pixelminimum?\n",
      "\n",
      "Beitrag\n",
      "\n",
      "Skizze: Leitfaden Instagram Postings\n",
      "\n",
      "1. Welchen Zweck hat das Posting? Überleg dir klare Ziele für das Posting 2. Welches Posting-Format (Reel, Story, Beitrag) wählst du? Habe das zugehörige Video-Format im Hinterkopf (s.u. “Technische Hintergründe”) 3. Werte und Ziele - Check! Überprüfe ob dein Vorhaben im Einklang steht: 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23.\n",
      "\n",
      "4. Wie bindest du die Community mit ein? Umfragen, Countdown-Sticker, zum Kommentieren auffordern (z.B. heute haben wir was zu python gelernt….was ist eure liebste Programmiersprache?),... 5. Welche Hashtags passen? Liste Hashtags: 6. Gestaltungsrichtlinen eingehalten?\n",
      "\n",
      "Schriftart: - Sprache (formell /Informell) - Tonalität und Hintergrundmusik - Farbschema: - - Postingstil (minimalistisch, bunt, street, etc.): - Filter und Bildbearbeitung: Logoplatzierung:\n",
      "\n",
      "Technische Hintergünde:\n",
      "\n",
      "Story\n",
      "\n",
      "Videolänge bis zu 15 Sek pro Story - Hochformat (9:16) - Pixelminimum?\n",
      "\n",
      "Beitrag\n",
      "\n",
      "Skizze: Leitfaden Instagram Postings\n",
      "\n",
      "1. Welchen Zweck hat das Posting? Überleg dir klare Ziele für das Posting 2. Welches Posting-Format (Reel, Story, Beitrag) wählst du? Habe das zugehörige Video-Format im Hinterkopf (s.u. “Technische Hintergründe”) 3. Werte und Ziele - Check! Überprüfe ob dein Vorhaben im Einklang steht: 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23.\n",
      "\n",
      "4. Wie bindest du die Community mit ein? Umfragen, Countdown-Sticker, zum Kommentieren auffordern (z.B. heute haben wir was zu python gelernt….was ist eure liebste Programmiersprache?),... 5. Welche Hashtags passen? Liste Hashtags: 6. Gestaltungsrichtlinen eingehalten?\n",
      "\n",
      "Schriftart: - Sprache (formell /Informell) - Tonalität und Hintergrundmusik - Farbschema: - - Postingstil (minimalistisch, bunt, street, etc.): - Filter und Bildbearbeitung: Logoplatzierung:\n",
      "\n",
      "Technische Hintergünde:\n",
      "\n",
      "Story\n",
      "\n",
      "Videolänge bis zu 15 Sek pro Story - Hochformat (9:16) - Pixelminimum?\n",
      "\n",
      "Beitrag\n",
      "\n",
      "        Frage:\n",
      "        was sind die Technische Hintergünde für einen beitrag?\n",
      "\n",
      "        Bitte beachte bei deiner Antwort:\n",
      "        - Gehe spezifisch auf die Bedürfnisse des Nutzers ein.\n",
      "        - Nur auf Nachfrage! Biete praktische Tipps für Social-Media-Posts im Unternehmenskontext.\n",
      "        - Unterstütze neue Kollegen mit klaren Anweisungen und Ressourcen.\n",
      "        - Verwende eine positive und motivierende Sprache.\n",
      "        - Halte dich kurze und beantworte im ersten schritt erst mal nur die Nutzer-Frage.\n",
      "        - Gebe mir Antwort wenn passend als Aufzählung auf.\n",
      "\n",
      "        Antwort:\n",
      "        \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Assistant: Die technischen Hintergründe für einen Instagram-Beitrag sind leider nicht im vorliegenden Leitfaden spezifiziert.  Der Leitfaden erwähnt lediglich die technischen Spezifikationen für *Stories*.  Um dir weiterhelfen zu können, brauche ich mehr Informationen.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "print(\"01 - Initialize embedding model\")\n",
    "embedding_model = build_embedding_model(EMBEDDING_MODEL, PROJECT_ID)\n",
    "\n",
    "print(\"02 - Initialize BQVector Storage\")\n",
    "bq_store = initialize_bqvector(PROJECT_ID,LOCATION,DATASET_ID,TABLE_ID,embedding_model)\n",
    "\n",
    "print(\"03 - Langchain retriever\")\n",
    "langchain_retriever = bq_store.as_retriever()\n",
    "\n",
    "print(\"04 - Build System Prompt\")\n",
    "custom_prompt = build_system_prompt()\n",
    "\n",
    "print(\"05 - Initialize LLM model\")\n",
    "llm = initialize_llm_model(MODEL_NAME)\n",
    "\n",
    "print(\"06 - Initialize meory\")\n",
    "memory = create_memory_buffer()\n",
    "\n",
    "print(\"07 - Conversational chain\")\n",
    "conversational_chain = convo_chain(llm, langchain_retriever, memory, custom_prompt)\n",
    "\n",
    "# Start the chat\n",
    "chat_with_agent(conversational_chain)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
